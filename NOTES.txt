

1. Introduction

Data Structures: to store data in an efficient way. When we use the most proper data structures for the algorithm it boost up running speed of that. That is why we might need different data structures.

ADT (Abstract Data Type) is just spesfification or model (logical description) of certain data structures. ADT does not spesifies implementation it just define what methods so data structure will have, so 
we define the basic behavior. ADT is language independent. For example, Queue is ADT and should have push(), pop() and peek() methods.

On the other side "Data Structures" are concrete implementation of ADT. For example ArrayList, Queue, HashMap, Array is a some the data structure in Java. 
(Note sometimes ADT and Data Structres are having same name but dont mix them)

1. ARRAYS

Is a collection of elements each identified by an array index. Index starts from 0. 
Array is data structure in order to store collection of data with same type. Array can have as many dimensien as we want. 

PROS
1) We can use random access because of its key. array[4]. (O(1) time complexity)
2) Very easy to implement and use.
3) Very fast.


CONS
1) We have to know size of array in compile time.
2) If it is full in order to have more items inside ti we should create new nigger array and move all of its value inot there whihc will take O(N) time complexity.
3) It is not able to store data with different types



ARRAY OPERATIONS AND THEIR TIME COMPLEXITIES
1) Adding new item to end of array. (Of course if array is not full). O(1).
2) Inserting item into spesific index. (Of course if array is not full) O(N) in the worst scenario.

3) Removing last item of array. O(1).
4) Removing item by array index. O(N). in the worst scenario.

5) Retriving data by its index. O(1)
6) Searching value by its value. O(N). Because we should iterate array.


ArrayList is resizable-array implementation of List interface in java. It permtis all elements included null. (This class is roughly equivalent to Vector, except that it is unsynchronized.)

The size, isEmpty, get, set, iterator, and listIterator operations run in constant time. The add operation runs in amortized constant time, that is, adding n elements requires O(n) time. 
All of the other operations run in linear time (roughly speaking). 

Each ArrayList instance has a capacity. The capacity is the size of the array used to store the elements in the list. It is always at least as large as the list size. As elements are added 
to an ArrayList, its capacity grows automatically. The details of the growth policy are not specified beyond the fact that adding an element has constant amortized time cost.

An application can increase the capacity of an ArrayList instance before adding a large number of elements using the ensureCapacity operation. This may reduce the amount of incremental reallocation.

Note that this implementation is not synchronized. If multiple threads access an ArrayList instance concurrently, and at least one of the threads modifies the list structurally, it must be 
synchronized externally. (A structural modification is any operation that adds or deletes one or more elements, or explicitly resizes the backing array; merely setting the value of an element 
is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be "wrapped" using 
the Collections.synchronizedList method. This is best done at creation time, to prevent accidental unsynchronized access to the list:

   List list = Collections.synchronizedList(new ArrayList(...));

The iterators returned by this class's iterator and listIterator methods are fail-fast: if the list is structurally modified at any time after the iterator is created, in any way except through the 
iterator's own remove or add methods, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, 
non-deterministic behavior at an undetermined time in the future.

Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. 
Fail-fast iterators throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: the fail-fast 
behavior of iterators should be used only to detect bugs.


3. LINKED LISTS

LinkedList are composed of nodes and references or pointers from one node to another. The last reference pointing to null.

Node1 -> Node2 -> Node3 -> NULL

A single Node containing 2 important data.
1) Data -> Integer, Double .. Custom object.. etc.
2) Reference to next Node 


About Linked lists
1) Simple and very common Data structure
2) They can bu used to implement several other common data types such as Queue, Stack.
3) Simple Linked Lists by themself does not allow random access to the data. So we can use getItem(index).
4) Many basic operations such as obtaining the last node of list, finding node that contains a given data or locating the place where new node should be inserted - requires sequential scanning of
most or all of the list elements. 


PROS
1) LinkedList is dynamic data structure (Arrays are not!!!)
2) It can allocate needed memory in run-time
3) Very efficient if we want to manupulate the first element
4) Easy implementation
5) Can store items with different size. (And array assumes every item are with same type)
6) It is easier for LinkedList to grow organically. An array's size to be needed in compile time or recrate when it needs to grow.

CONS
1) Waste of memory because of references to next node
2) Nodes in the list should be read from beginning and that is why random access will NOT run in O(1) time like an array.
3) Single linkedLists are extremly difficult to for reverse travering (To read backward or iterate backward). Because nodes does not contain refernces to previous node. Solution is Double Linked List. But
disadvantages is more waste of memory because this time every node contains 2 references - one to previous and second to next node.



SINGLE LINKEDLIST OPERATIONS AND THEIR TIME COMPLEXITIES
1) Retreving first item of list. O(1)
2) Retreving item at a given index. O(N) 

3) Removing first item of list. O(1)
4) Removing an item at a given index. O(N)


LINKEDLIST IN JAVA

Doubly-linked list implementation of the List and Deque interfaces. Implements all optional list operations, and permits all elements (including null).
All of the operations perform as could be expected for a doubly-linked list. Operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the specified index.

Note that this implementation is not synchronized. If multiple threads access a linked list concurrently, and at least one of the threads modifies the list structurally, it must be synchronized externally. 
(A structural modification is any operation that adds or deletes one or more elements; merely setting the value of an element is not a structural modification.) This is typically accomplished by 
synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be "wrapped" using the Collections.synchronizedList method. This is best done at creation time, 
to prevent accidental unsynchronized access to the list:

   List list = Collections.synchronizedList(new LinkedList(...));

The iterators returned by this class's iterator and listIterator methods are fail-fast: if the list is structurally modified at any time after the iterator is created, in any way except through the 
Iterator's own remove or add methods, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than 
risking arbitrary, non-deterministic behavior at an undetermined time in the future.

Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. 
Fail-fast iterators throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: the fail-fast 
behavior of iterators should be used only to detect bugs.

This class is a member of the Java Collections Framework.


3. STACKS

In computer science, a stack is an abstract data type that serves as a collection of elements, with two main principal operations:

- Push, which adds an element to the collection, and
- Pop, which removes the most recently added element that was not yet removed.

Basic operations are 
- peek() - returning the last inserted item from stack
- pop() - removing the last inserted item from stack
- push() - adding new item to stack

Stack has LIFO (Last in First out) structure.
In most high level languagaes stack can be implemented easyly with array or linked list.


STACK MEMORY
- The most important application of stack abstract data type. 
- It is a special region of memory in the RAM. 
- The details of how to store data in stack are normally hidden in high-level programming languages.
- It keeps track of point to which each active subrutine should return control when it finishes executing. 
- Stores temporaly variables created by each fundtion.
- Stack memory is limited
- Every time local variables are created they are pushed into stack memory.Once method ends those variables will be gone from stack memory.

HEAP MEMORY
- The region of the meomory that is not managed automatically for you.
- This is large part of memory. (Unlike stack)
- In JAVA references types and objects are stored in heap memory
- We have to deallocate the chunks because heap memory is not managed autamitaclly. But in java there is also garbage collector which helps us in this sense
- If we would not remove chunks from heap and not manage it correctly it will lead us to MEMORY LEAK.
- Heap memory is slower than Stack


DIFFERENCES OF STACK AND HEAP
HEAP
- no size limit
- slow access
- objects and references types will be stored here
- we should manage memory and remove chunks

STACK
- size limit
- fast access
- local variables are stored
- space efficienlt managed by CPU


STACK IN JAVA
public class Stack<E>
extends Vector<E>
The Stack class represents a last-in-first-out (LIFO) stack of objects. It extends class Vector with five operations that allow a vector to be treated as a stack. The usual push and pop operations are 
provided, as well as a method to peek at the top item on the stack, a method to test for whether the stack is empty, and a method to search the stack for an item and discover how far it is from the top.
When a stack is first created, it contains no items.

A more complete and consistent set of LIFO stack operations is provided by the Deque interface and its implementations, which should be used in preference to this class. For example:

   
   Deque<Integer> stack = new ArrayDeque<Integer>();

Since:
JAVA 1.0

3. Queues

In computer science, a queue is a collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the
other end of the sequence.

- Abstract data type
- Fifo structure
- Basci operations are, dequeue(), enqueue(), peek();
- It can be implemented with help of dynamic array and linked list

Operations
- enqueue(Object o) adding an item at the end of the queue
- dequeue() removing an item at top of the queue
- peek() retrieving an item at the top of the queue.

Most popular applications
- when resource is shared by multiply consumers (threads) we store them in queue. 
- For example CPU Scheduling
- when data is trasferred asynchrously 
- For example: IO Buffers


Queue in JDK
https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Queue.html
https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/PriorityQueue.html


4. Binary Search Trees (BST)

In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree whose internal nodes each store a key greater than all the keys in the node's 
left subtree and less than those in its right subtree. A binary tree is a type of data structure for storing data such as numbers in an organized way. Binary search trees allow binary search for 
fast lookup, addition and removal of data items, and can be used to implement dynamic sets and lookup tables. The order of nodes in a BST means that each comparison skips about half of the remaining tree, 
so the whole lookup takes time proportional to the binary logarithm of the number of items stored in the tree. This is much better than the linear time required to find items by key in an (unsorted) array, 
but slower than the corresponding operations on hash tables.

In BST insertion and searching operation takes always O(logN) time complexity.

During the deletion of node from BST we might find ourself in 3 sort of different stiuation. Let's consider them one by one.

1) Node we wanna delete is a leaf node. Leaf node of tree is the node which does not have any child node. So in this case our job is gonna be very easy. Basically we will just set that node to null and that is all. Time 
complexity of this is gonna be O(logN) .
2) The node we wanna delete might have only 1 child. Does not matter on the right or left. It is also very easy job for us. We will replace this node with its that only child. And that is all. It will
also reqire O(logN) .
3) The node we wanna delete has 2 child. This is a little bit complex stiuation for us. There are several ways to handle this. One of the easiest way is below:
Just after finding the node we wanna remove will either the bigest node in the left subtree of that or smallest node in the right subtree of that and swap them. After that we will absolutely have one of the stiuation above for the node
we wanted delete. And we know how to handle them. So it will also take O(logN) time complexity.


Traversal of BST
The method to chouse to traverse the BST might be important. There some common ways to do it.
1) In-order traversal. With this method we start from left node then go to root then go to right recursively. It will give us sorted traversal.
2) Pre-order traversal. With this method we visit root then go to left then right recursively.
3) Post-order traversal. With this method we first visit left then go to right then root recursively.

Generally if the tree becomes very unbalances (for example we create a treee from sorted arrays then it will have only right childs) all the O(logN) operations are going to closer to O(N) linear time complexity. That is why
it is very important to keep tree as much as possible balanced.

Predecessor - > The bigest Item on the left subtree of given node
Successor -> The smallest item on the right sub tree of given node

5. BALANCED TREE AVL TREE

We learned that BST are way to better than LinkedList for searching operations but in the case it is balanced. If we would create a BST from sorted array we will not get balanced BST
instead we will get LinkedList which will give us O(N) time complexity for searching. But AVL tree is balanced BST. So AVL Tree are BST only with 1 important differ. If tree is AVL 
height of 2 child subtree of every node differ by at most one. So it condition never let tree become unbalanced it will alwys make sure tree is balanced.

All the operations are same in AVL tree with BST. (Because eventually AVL is BST tree). Only differ is during the adding new node to Tree we will need check whether tree remains balanced
or we should adjust it. AVL tree are faster than Red Black tree (Red Black tree is also BST) but construction is more difficult than that. That is why nowadays Red Black trees are more popular.

In Order to keep AVL balanced we might need rotations.
We might have 4 kind of cases.
1) Left heavy -> Node has left child and that left child olsa has left child
Solution. We should rotate the root (root of this subtree) to right.

2) Right heavy -> Node has right node and that right has also right. 
Solution. We shodul rotate the left

3) Left - right -> Node has left and that left has only right child.
Solution. First take left of root and rotate to left. After that we will have the case as same as 1st case (heavy left). To solve this ofcourse rotate root to right.

4) Right - left -> Node has right and that right has only left child.
Solution. First right of root and rotate to right. Then we will have case as same as 2nd (heavy right). To solve this rotate the root to left.


Operations of AVL Tree

insert() - > O(N * logN) time complexity. because after adding new value We should check the tree whther it is balanced or not. So of not we will need rotate the some nodes in order to
achive balanced tree. And in worst cases we might need to rotate all the nodes in the tree that is why we consider time complexity of insertion operation is O(N * logN);

Traversal -> O(logN) as same as normal BST.

Red black trees are more papular than AVL tree becuse after every insertion or deletion we might need rotate some nodes.


6. RED BLACK TREE
Red-black tree is also BST as well as AVL Tree. And it helps us to solve same problem related BST. Because when BST get unbalanced it louses its efficiency RED-BLACK tree tries to keep BST unbalanced. So Red-black tree is
balanced BST as same as AVL tree is.

Properties of Red-black tree
1) Each node is eidher RED or BLACK
2) The root node is always BLACK.
3) Every RED node should have 2 BLACK childs. (Children of RED should be BLACK). And of courses in this cases RED nodes will have always BLACK parent. 
4) Every path from given node to any of its descentant (NIL/NULL) noded should contain same number of BLACK nodes.

RED BLACK Tree vs AVL Tree

Red-black tree
- Linux Kernel relies on heavly Red-black tree data structure
- Insertion is fast Because it is not rigidly balanced. We dont bother to keep tree as balanced as possible
- For an insert intensive task use Red-black tree
- java.util.TreeMap, java.util.TreeSet uses Red-black tree data structure 

AVL Tree
- Rigidly balanced tree and hense provides faster look-up operation
- For a look-up intensive task use AVL
- Insertion and deletion is not so fast because we keep balancing the tree.

After insertion we should check nodes from bottom to top whether Is there red-black tree properties violation. If there we shoud fix it with help of rotation and recoloring. When we insert new node
into Tree its default color is red. So after insertion during the checking we might have same kind of case which we have different type solution for them.

CASE 1.
a) Inserted node is the right child of its parent, its parent is the left child of its parent, parent and uncle (uncle node is other child of nodes grandfather) are RED.
SOLUTION: Recoloring its parent, grandparent and uncle node. So After coloring parent and uncle are going to be BLACK, grandparent is going to be RED.

b) Inserted node is left child of its parent, its parent is right child of its parent and parent and uncle node are RED. 
SOLUTION: Recoloring Its parent, grandparent and uncle color. So after recoloring operation parent and uncle are going to be BLACK, grandparent is going to be RED;

CASE 2.
a) Inserted node is a right child, parent is left. Parent is RED, uncle is BLACK.
Solution: Left rotation of parent node.

b) Inserted node is left child, parent is right. Parent is RED,uncle is BLACK.
Solution: Right rotation of parent.

CASE 3.
a) Inserted node is left child, parent is left child. parent is RED, uncle is BLACK.
Solution: First we should Right rotate the gradparent then swap the color of parent and grandfather

b) Inserted node is right child, parent is right child. Parent is RED, uncle is BLACK.
Solution: First left rotation of grandparent then swap the colors of grandparent an parent.

CASE 4:
a) Inserted node is left child, parent is left child. Parent is RED and uncle is RED.
Solution: Recoloring parent to BLACK, uncle to BLACK and grandparent to RED;

b) Inserted node is right child, parent is right child. Parent is RED and uncle is RED.
Solution: Recoloring parent to BLACK, uncle to BLACK, grandparent to RED.



7. SPLAY TREE

Splay tree is al BST so all properties which were true for BST are the same for Splay tree. But splay tree is a little bit different from other special trype of BST which we learned such as AVl and Red-Black tree. Because aim of them were
keeping tree as balanced as possible. Specially AVL tree is very serious about it. But it is not the aim of the Splay tree. Aim of Splay tree is providing very fast to the items which were accessed recently.

About Splay tree
- It is type of Binary search treee(BST)
- Most operations have O(logN) complexity but some are very slow O(N)
- Unlike AVL tree it is not stricly balanced that is why it is faster
- It is easy to implement
- The most popular data strucre in the industry
- Fast access to the elements which were accessed recently
- It can be used for Cache implemetation

FIND operation
Find operation is exactly the same as how it is for General BST but with only one difference. After finding the item in the tree we should move it to the root of the by help of rotations. In this way for the next find operations this item
will be ble to be accedded very fast. Because it 'll be root. And it is called "splaying". We might need to make several rotation operation in order to move it to root.

After finding the item in the tree in order to make a rotation we should choouse which strateg to use. Because we might have 3 kind of cases there.
1) Zig-zag
2) Zig-zig
3) Zig


ZIG-ZAG
a) The item is left child , parent of it is right child.
SOLUTION: Right rotation of the item.

b) The item is right child , parent is left child.
SOLUTION: Left rotation of the item.


ZIG-ZIG
a) The item is left child, parent is left as well.
SOLUTION: Right rotation of the item
b) The item is right child, parent is right as well.
SOLUTION: Left rotation of the item

ZIG
a) The item is the left child of the root
SOLUTION: Right rotation of the item

b) The item is the right child of the root
SOLUTION: Left rotation the item

NOTE: Bsically if the node is the left child just rotate to right, but if the item is the right child just rotate to the left.


8. B-TREE

B-Tree is NOT BST but it has very similar characteristics. Actually every BST is B-tree. B-tree is general version of BST. BST is one of the variant of it.

- B-tree are slef balancing like data structure.
- Operations. insertion deletion, sequencial access and searching are supported.
- Most of the operations has O(logN) time complexity.
- Important diffirent from BST is each node can have more then 2 children and each node can have more than 1 keys (data).
- B-tree is optimized for sytems which reads and writes large amount of data
- Is is commonly used in databases and filesystems.

Lets imagine the node stores 2 keys in it. then it will have 2 branch hanse 3 subtree. it is al3wys like this. if the node contains m elements then branching factor is m+1.
But the basic principle of BST is also true here it means always the data stored in the left subtee of key is smaller than key. In the BST node itself keeps refernces to his subtree or branches
but in B-tree keys of nodes keeps refernces to his subtree s. Even they might have common references. For example node has 2 keys then 3 subtree. That subtree in the middle or second one is common.
Because it is right subtree of 1st key and in the meantime left subtree of second key.

Also nodes dont need to be entirelly full. They might contain sometimes empty keys. B-tree dont need ot be balanced stricly such as AVl tree. That is why it waste memory more than AVL.

In general
- If the node can contain m keys it can contain m+1 subtree at most
- Every node is at leats half full
- If the count of elements in the node is less than m/2 (means node is more empty than half full) it should be merged with another node
- The root node has at leats 2 childeren if it is not a leaf node
- Every path from root to the leaf contains same amount of node 
- All keys stored in the node which is common node of 2 keys in his parent node are between the value of his parents keys. For example nde contain 2 elemets. then it have 3 subtree. the values stored in the middle subtree
should be beetwen those 2 keys of his parent node.
- Items in the each node are stored in sorted order


One of the mos popular variant of B-tree is called 2-3 B-tree.
Properties of 2-3 B-tree are below:
- Every node can have 2 keys or elements at most.
- Every node can have 3 children at most
- All leaves are at same level
- All data is kept in sorted order inside the node

Most of the time when we work wit HashTable, AVL etc. we never consider memory access time because we know all the data we are using is stored in the RAM. And it is true. But sometimes we have to deal very big amount of data
even bigger than size of RAM. So Because the those big data not stored in the RAM it is stored in the External disk or hard drive whatever but always memory access is slower than RAM. in that kid of case we need considering
Memory access time when we chose the data structure we'll use. We should use the data structure which requred less memory access because this operation is costy for us. For example databases, file systems.
And in this kind of scenarios B-tree cames to help. It outperforms BST when memory access time is considered from external disk. Bceause height of tree is aways smaller than BST (because every node can contain more than 1 key)
total disk access is significantly reduced for B-tree comparing to BST.
We shoudl keep in mind BST is actually better than B-tree when consediring RAM (fast access meory), But B-tree is better than BST when dealing with slow memory access such as external disk.

Working strategy of HARD DRIVE and RAM is different. From HARD DISK yes access time is vay to smallar than RAM (even more than 10000 times on avarege). But hard disk reads big amount of time in each reading than return back.
So for example even though we need just an integer which is 4 BYTE , when we need access than from hard disk hard disk actually reads 4096 BYTE. And that is to keep a lot of keys in the each node heps us when dealing with
external disk. So during the searching instead of recirsive methods and try to find where is the given node we will have more keys in the one node that will give us chanse to find given node
in less recursion comparing to BST.

9. PRIORITY QUEUE

- It is an abstract data type such as stack and queue
- But every item has addititional priority. A priority value
- In Priority queue the item with higer priority is served before the item with lover pririty
- Priority queue is usually implemented with heps but it can also be implemented with help of self balancing tree

OPERATIONS
1) insertWithPriority(item, priority);
This method will inset an item with priority. Just keep in mind some times if the type of item in the queue is integer or number , value of item itself can bu used as priority. So in this way
we will have a sorted queue which will retrive the data in DESC order

2) getHighestPriorityItem();
Return the item with highest priority. As I mentioned earlier if we define the priority value as same as the value of item this method will return the biggest item from queue.
Keep in mid if Priority queue is implemented with help of heaps after retreving the the item we will need do reconstruct the heap. Because after retreving te item we should remove that from the list.

3) peek();
It will jst the item with hhightest priority but will net remove the item from queue

10. HEAP

- It is basically a binarry tree but with sum differences
- There are 2 main diferent heap type. Minimum heap and Maximum heap
- in Max Heap values of children are always smaller or equal to their parent. And The root element is always have the highest value in the tree
- In a Min heap the values of children are alwsays bigger or equal to perent and the root element is alwys the smallest one
- It is complete and balanced tree. We should keep in mind inserting process here different. In the binnary tree we used to check if the value is bigger it should be right child and etc. bt here we dont have that 
requirement. Only requirement is we should put the item into next avaliable space which is finfing from left to right. Here we just try to keep tree walys balanced but visiually. We dont bother about the values.
Regarding the comprassion of values only requirement is if it is for example max tree then children should be smaller or equal to their parent. But that is all. We dont spesify anything about smaller should be left or etc.
We just kind of trying to fill tree layer by layer. After completing for exmple second layer (the layer after root) we move forwayd to 3rd layer from left to right.

- The heap is one maximally eficient implementation of priority queue abstract data type. (Even priority queues often referred as heaps regardless of how they are implemented)
- Even thought it has same name as HEAP memory but it has nothing to do with that
- In the binary heap every parent can have 2 children at most


Inserting operations
Lets imagine it is max heap. Basicaly we just insert the new item to next avaliable spave firstly after that we check the Max heap properties that if is it violated. If we see there is a cild which is bigger that its parent we simple
swap them and keep checking until the root. And it will take O(N) time complexity

Removal operation
Lets imagine we have Max heap again. And we wanna remove the hightest value which is root. We simple remove it then take the last item in the tree and put to the root. After that we start checking the Max hep properity as well to know that if it 
is violated or not. We simple checking the new root item with ites bigger child and if it is bigger that the new root (mostly yes) we swap and so on. And overall it removal operation will take O(logN) time complexity.
JUST keep in your mind that if would like to remove an arbitrary item from the heap it will take N(N) time complexity because we should first the item with iterating the whole tree and after that remove it.


HEAPSORT
- It is a comparasion based sorting algorithm
- It uses heap data structure rther than linear time search to find the biggest item
- A bit slower in practice in most fo the machines than a well implemented quick sort. But it has advantage of more favorable worst case time complexity. O (N * LogN)
- It is in place algorithm

Basically this algorithm is about that we create the Heap from given items after that first return the root item whih is biggest in Max heap. after that we swap that with latest item in the heap and very importantly put to flag to
this item in order to know we will not consider this anymore. It is kind of excluding it from Heap. And after this we sheck whether is there property of Max heap violated or not. If yes we swap so on. After this operation we will have again
valid Max Heap in our hand (ecept that marked and exclused item. It can stay in the end even thought violates max heap property. because it is marked already we no longer consider that). And repeating again. taking the root item and so on.
Because we have N items in the heap we might need apply swapping operation to all of them in the worst case and that is will it will take O(N * logN) time complexity

PriorityQueue implementation in JDK
https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/PriorityQueue.html

10. ASSOCIATIVE ARRAY

- Associative array or dictioanary or map is abstract data type
- Composed of collection of key value pairs where each key appers only once
- Most of the time we implement Associative array with HashTable but BST is also can be used

Operations
- Adding key value pair to the collection
- Rempvong key value pair from collection
- Updating value of given key
- Retrieving the value of the given key

A Hashtable or Hashmap or Dictionary is a Data structure which implement Associative Array ADT. Hashtable uses hash function to compute the index also called hash code into array of bucket or slots which desired value can be found.
During the look up Hashtable again takes the key and generate the hash code to find that  in which should can the key pair with given key found.


About Hashtable 
If we wanna to get our lookup operation in O(1) time we might use Array like structure where we can retrieve the value with given index in O(1). Hashtable uses also same strategy but here we should find based on key in which index
we should store the given key value pari. Hash function is for it. Hash function taking the gey and generating the index number which is beetwen the range of 0 and (array.length - 1). And after that it stores given key value in that index.
During the lookup it does same hashing function and finding thekey value pair in the slot where it should be. The easiest way to do it after fenerating the hash from given key we shoudl mod it (has(key) % array.length). Because it makes sure
we will ways get value fro which is beetwen the range of (0 and array.length) whch is very important for us.

COLLISION
Because in the end the array which we will use as slots or buckets has limited amount of size and we will have stiuation he index for different keys which is generated for storing key value pairs in the bucket will be same. In tis stiuation called collision.
We have some strategies to handle this kind of stiuation.

1. Chaining
Basically we store the value in in linked list. In every slot of array actually stores the linked list. In this way if we would have same index generated from hash function for given 2 keys they both will be stored in the same index as 
nodes of linked list. Implementation of it very easy but we should keep in our mind that if our hash function would generate same index for a lot of keys in the end we will louse O(1) time complexity especially for look up operation and even in the wors
 case it will be O(N). That is why we will need to make sure our hash function can distribute the value well beetwen the array slots.

2. Open addressing
Here instead of creating a linked list and stores value there we chose different method. If we would notice that the slot of array with given index is full we for example going to next avaliable slot and store the key value there. And we might
chouse here also different ways ofr finding nextavaliable slots. For example
a) Linear probbing
If slot is not empty go to next slot if it is also busy go to next one so on.

b) Quatratic probbing
If the slot is busy we try 1,2,4,8.. for away slot and try to find empty one.

c) Rehashing
We hash the result again in order to find empty slot

Time compleixt of operations
- Searching -> O(1), O(N) in the worst case
- Inserting -> O(1), O(N) in the worst case
- Removing -> O(1), O(N) in the worst case


Space complexity is -> O(N)

Dynamic resizing
We learned that how to handle collissions. But to avouid collision happening a lot we can dynamically reside the Hashtable. It means if we check and see there a lot of entries in the hashtable compared its slots size
we know in this kind of stiuation collision can happen a lot. And that is why we resize de underline array. But it is very costy operation because we should hash every entries one by one again in order to know
in which index of new rezied array they should be stored. So rezizing wil, take O(N) time complexity.

How we dice dynamic rezising in needed ? We can know this after calculating LOAD FACTOR of hashtable. LOAD FACTOR = countOfEntries divided by countOfArraySlots. n/m
For example we have an array underline with 16 slot. And we see there is 4 entries in the hashtable. It means load factor = 0.25 which is not a big number. For example in Java after Load factor excided 0.75 HashMap resize its
underline array. 


Map implementations in JDK
TreeMap -> It is sorted may (by keys) and dont accept any null key but accpets null values. And the keys shoudl implement Comparable interface or we should use the constructor of which we can pass our custom Comparator.
HashTable -> syncronized Map implementation. IAnd it is slow because all methods are syncronized.
HashMap -> accpets only 1 null key and how much ever we want null values. There is no order guarantin like a TreeMap. And it is not syncronized beasically it is faster than HashTable.



11. Trie Data Structure

- Trie DS (digital Tree or prefix Tree) is tree like DS
- Very similar to BST but of course with some additional feature
- Usually they are used as Associative Arrays (Dictionary or hashmap) in order to store key-value pairs but where keys are usually string
- Very important ! Trie outperforms hashing based Associative Arrays. (Means Trie doing better than HashTable)

What is the motivation behind Trie DS ?
We have already learned about Hashmap which is also DS which allows us to store key-value pairs efficiently. But there are 2 main concern here. First of all
there is collision problem on hashmap. Because it is not possible to create perfect hash function sometimes collision happens. And because of the collision
we expect Hashmap will run on O(N) time complexity in the worst case. Second concern is sorting feature. As we learned about HashMap it does not have
sorting feature built in. And it is also kind of one of the disadvantage of HashMap.


About Tries
- It is DS is used to implement Associative Array ADT
- Unlike BST no node in the Trie stores key associative with given node.
- Its position in the tree defines the key with which is associated
- All the descendants of a node have common prefix of string associated with that node
- The root is associated with empty string
- Not all node contains value

Basically it is like a tree but every node stores key which is 1 character of alphabet. For example let's imagine we use only english alphabet which has 26 cha-
racters. As we told earlier root node stores empty string. after than root node will have at most 26 node. And every child of root also will have at most
26 nodes so on... Every node stores only 1 character that is why for example we wanna insert (put("ab", someValue)) "ab" key into Trie. Then it's depth will be 2
because we will first insert node with "a" key into root after than another node with "b" node into that new node which is inserted with "a" key.
So last view is (root, "") -> ("a") -> ("b", someValue)  .
So as we can see from here we might have way more nodes comparing to BST. Because here every node might have 26 nodes. So That is why Trie is not memory efficient.
But as we can see from here also it will work quite fast. Especially during searching operation based on  characters of key we will easly track the nodes and
find the value if it is stored. So that is why we say time complexity of searching operation in Trie depends on length of the characters in the given key. So unlike
a hashmap it is not depend on the count of the items in the Trie. That is why we no more have here the worst case O(N). Our time complexity is totally relies
length of the key which is really good comparing to hashmap.

So as we talked also earlier always if we wanna have faster DS it is not very memory efficient.

- Operations

- Insert O(M); M = length of the key
During insert based on the characters of key we create the node with each letter (from first letter until end) if it does not exists and in the end when we reach the
leaf node we insert the value there. But another important thing here is because each node might have a lot of node (26 for english alphabet) in which side (left or right)
the node should be stored is important. Here when we insert the node node with new character into the parent  we should compare the value with the value of the node.
if the letter we wanna insert is smaller (unicode value) than node then we should insert this new node as left child. If not then right child. with this way
children of parent will be stored as sorted (from left to right) in the node.

- Search O(M); M = length of the key
During the search based on letters of given node (from left to end) we iterate through Trie and find the leaf node. Some times in the middle of the characters of key
we can notice there no anymore the node with next letter which we are looking for. It means this key does not exits in the Trie. This kind of scenarios are even better
because here time complexity even smaller than length of the characters. Which is concerned very very fast. But if we reach the the last letter of the key
and in the associativeArrayWithTrie then we know the value might be stored in that node. So if yes we retrieve the value.

- Sorting O(N); N =  count of nodes in the Trie
Sorting is quite easy. Simply we make in-order traversal (left->parent->right) which will give us value in sorted way.

Now days Autocomplete feature in a input is very popular in the applications or websites. Such as google search etc. And this feature can be done with the help of
Trie data structure.


Hashing based Associative Array vs Trie based associative array
- For searching operation Trie based AA is way too better than hashing based AA. Because in the case of Trie running time of searching
is depend on size of the given key M. And in the worst case it is O(M). But in the case of hashing because of the collision problem it is
depend on the count of the items in the hashtable N. So running time is O(N).
- There is no collision problem in case of trie based AA
- Trie support sorting feature
- Hashing based AA is way to better than Trie based when memory management concern. Because When we create hashtable it is just an array we keep data and
first of all we have quick access (reading from RAM) secondly because we use array we dont waste a lot of memory. But in case of trie we store data as a node.
And it will require a lot of reading operation from Memory device.
- If we are using external memory which is reading operation is very slow in that case Hashing based AA will be better for us because it has fewer reading operation.


12. Ternary Search Tree (TST)

TST is actualy special type of Trie or prefix Tree. Difference is nodes of TST  can have at most 3 children.
TST is more memory efficient than Trie but Trie is faster than TST. Is is also used for same reasons which Trie is used. Mostly to implement
Associative array or to implement spell-checking (autocomplete feature).

















	
































































