

1. Introduction

Data Structures: to store data in an efficient way. When we use the most proper data structures for the algorithm it boost up running speed of that. That is why we might need different data structures.

ADT (Abstract Data Type) is just spesfification or model (logical description) of certain data structures. ADT does not spesifies implementation it just define what methods so data structure will have, so 
we define the basic behavior. ADT is language independent. For example, Queue is ADT and should have push(), pop() and peek() methods.

On the other side "Data Structures" are concrete implementation of ADT. For example ArrayList, Queue, HashMap, Array is a some the data structure in Java. 
(Note sometimes ADT and Data Structres are having same name but dont mix them)

1. ARRAYS

Is a collection of elements each identified by an array index. Index starts from 0. 
Array is data structure in order to store collection of data with same type. Array can have as many dimensien as we want. 

PROS
1) We can use random access because of its key. array[4]. (O(1) time complexity)
2) Very easy to implement and use.
3) Very fast.


CONS
1) We have to know size of array in compile time.
2) If it is full in order to have more items inside ti we should create new nigger array and move all of its value inot there whihc will take O(N) time complexity.
3) It is not able to store data with different types



ARRAY OPERATIONS AND THEIR TIME COMPLEXITIES
1) Adding new item to end of array. (Of course if array is not full). O(1).
2) Inserting item into spesific index. (Of course if array is not full) O(N) in the worst scenario.

3) Removing last item of array. O(1).
4) Removing item by array index. O(N). in the worst scenario.

5) Retriving data by its index. O(1)
6) Searching value by its value. O(N). Because we should iterate array.


ArrayList is resizable-array implementation of List interface in java. It permtis all elements included null. (This class is roughly equivalent to Vector, except that it is unsynchronized.)

The size, isEmpty, get, set, iterator, and listIterator operations run in constant time. The add operation runs in amortized constant time, that is, adding n elements requires O(n) time. 
All of the other operations run in linear time (roughly speaking). 

Each ArrayList instance has a capacity. The capacity is the size of the array used to store the elements in the list. It is always at least as large as the list size. As elements are added 
to an ArrayList, its capacity grows automatically. The details of the growth policy are not specified beyond the fact that adding an element has constant amortized time cost.

An application can increase the capacity of an ArrayList instance before adding a large number of elements using the ensureCapacity operation. This may reduce the amount of incremental reallocation.

Note that this implementation is not synchronized. If multiple threads access an ArrayList instance concurrently, and at least one of the threads modifies the list structurally, it must be 
synchronized externally. (A structural modification is any operation that adds or deletes one or more elements, or explicitly resizes the backing array; merely setting the value of an element 
is not a structural modification.) This is typically accomplished by synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be "wrapped" using 
the Collections.synchronizedList method. This is best done at creation time, to prevent accidental unsynchronized access to the list:

   List list = Collections.synchronizedList(new ArrayList(...));

The iterators returned by this class's iterator and listIterator methods are fail-fast: if the list is structurally modified at any time after the iterator is created, in any way except through the 
iterator's own remove or add methods, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, 
non-deterministic behavior at an undetermined time in the future.

Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. 
Fail-fast iterators throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: the fail-fast 
behavior of iterators should be used only to detect bugs.


3. LINKED LISTS

LinkedList are composed of nodes and references or pointers from one node to another. The last reference pointing to null.

Node1 -> Node2 -> Node3 -> NULL

A single Node containing 2 important data.
1) Data -> Integer, Double .. Custom object.. etc.
2) Reference to next Node 


About Linked lists
1) Simple and very common Data structure
2) They can bu used to implement several other common data types such as Queue, Stack.
3) Simple Linked Lists by themself does not allow random access to the data. So we can use getItem(index).
4) Many basic operations such as obtaining the last node of list, finding node that contains a given data or locating the place where new node should be inserted - requires sequential scanning of
most or all of the list elements. 


PROS
1) LinkedList is dynamic data structure (Arrays are not!!!)
2) It can allocate needed memory in run-time
3) Very efficient if we want to manupulate the first element
4) Easy implementation
5) Can store items with different size. (And array assumes every item are with same type)
6) It is easier for LinkedList to grow organically. An array's size to be needed in compile time or recrate when it needs to grow.

CONS
1) Waste of memory because of references to next node
2) Nodes in the list should be read from beginning and that is why random access will NOT run in O(1) time like an array.
3) Single linkedLists are extremly difficult to for reverse travering (To read backward or iterate backward). Because nodes does not contain refernces to previous node. Solution is Double Linked List. But
disadvantages is more waste of memory because this time every node contains 2 references - one to previous and second to next node.



SINGLE LINKEDLIST OPERATIONS AND THEIR TIME COMPLEXITIES
1) Retreving first item of list. O(1)
2) Retreving item at a given index. O(N) 

3) Removing first item of list. O(1)
4) Removing an item at a given index. O(N)


LINKEDLIST IN JAVA

Doubly-linked list implementation of the List and Deque interfaces. Implements all optional list operations, and permits all elements (including null).
All of the operations perform as could be expected for a doubly-linked list. Operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the specified index.

Note that this implementation is not synchronized. If multiple threads access a linked list concurrently, and at least one of the threads modifies the list structurally, it must be synchronized externally. 
(A structural modification is any operation that adds or deletes one or more elements; merely setting the value of an element is not a structural modification.) This is typically accomplished by 
synchronizing on some object that naturally encapsulates the list. If no such object exists, the list should be "wrapped" using the Collections.synchronizedList method. This is best done at creation time, 
to prevent accidental unsynchronized access to the list:

   List list = Collections.synchronizedList(new LinkedList(...));

The iterators returned by this class's iterator and listIterator methods are fail-fast: if the list is structurally modified at any time after the iterator is created, in any way except through the 
Iterator's own remove or add methods, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than 
risking arbitrary, non-deterministic behavior at an undetermined time in the future.

Note that the fail-fast behavior of an iterator cannot be guaranteed as it is, generally speaking, impossible to make any hard guarantees in the presence of unsynchronized concurrent modification. 
Fail-fast iterators throw ConcurrentModificationException on a best-effort basis. Therefore, it would be wrong to write a program that depended on this exception for its correctness: the fail-fast 
behavior of iterators should be used only to detect bugs.

This class is a member of the Java Collections Framework.


3. STACKS

In computer science, a stack is an abstract data type that serves as a collection of elements, with two main principal operations:

- Push, which adds an element to the collection, and
- Pop, which removes the most recently added element that was not yet removed.

Basic operations are 
- peek() - returning the last inserted item from stack
- pop() - removing the last inserted item from stack
- push() - adding new item to stack

Stack has LIFO (Last in First out) structure.
In most high level languagaes stack can be implemented easyly with array or linked list.


STACK MEMORY
- The most important application of stack abstract data type. 
- It is a special region of memory in the RAM. 
- The details of how to store data in stack are normally hidden in high-level programming languages.
- It keeps track of point to which each active subrutine should return control when it finishes executing. 
- Stores temporaly variables created by each fundtion.
- Stack memory is limited
- Every time local variables are created they are pushed into stack memory.Once method ends those variables will be gone from stack memory.

HEAP MEMORY
- The region of the meomory that is not managed automatically for you.
- This is large part of memory. (Unlike stack)
- In JAVA references types and objects are stored in heap memory
- We have to deallocate the chunks because heap memory is not managed autamitaclly. But in java there is also garbage collector which helps us in this sense
- If we would not remove chunks from heap and not manage it correctly it will lead us to MEMORY LEAK.
- Heap memory is slower than Stack


DIFFERENCES OF STACK AND HEAP
HEAP
- no size limit
- slow access
- objects and references types will be stored here
- we should manage memory and remove chunks

STACK
- size limit
- fast access
- local variables are stored
- space efficienlt managed by CPU


STACK IN JAVA
public class Stack<E>
extends Vector<E>
The Stack class represents a last-in-first-out (LIFO) stack of objects. It extends class Vector with five operations that allow a vector to be treated as a stack. The usual push and pop operations are 
provided, as well as a method to peek at the top item on the stack, a method to test for whether the stack is empty, and a method to search the stack for an item and discover how far it is from the top.
When a stack is first created, it contains no items.

A more complete and consistent set of LIFO stack operations is provided by the Deque interface and its implementations, which should be used in preference to this class. For example:

   
   Deque<Integer> stack = new ArrayDeque<Integer>();

Since:
JAVA 1.0

3. Queues

In computer science, a queue is a collection of entities that are maintained in a sequence and can be modified by the addition of entities at one end of the sequence and the removal of entities from the
other end of the sequence.

- Abstract data type
- Fifo structure
- Basci operations are, dequeue(), enqueue(), peek();
- It can be implemented with help of dynamic array and linked list

Operations
- enqueue(Object o) adding an item at the end of the queue
- dequeue() removing an item at top of the queue
- peek() retrieving an item at the top of the queue.

Most popular applications
- when resource is shared by multiply consumers (threads) we store them in queue. 
- For example CPU Scheduling
- when data is trasferred asynchrously 
- For example: IO Buffers


Queue in JDK
https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/Queue.html
https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/util/PriorityQueue.html


4. Binary Search Trees (BST)

In computer science, a binary search tree (BST), also called an ordered or sorted binary tree, is a rooted binary tree whose internal nodes each store a key greater than all the keys in the node's 
left subtree and less than those in its right subtree. A binary tree is a type of data structure for storing data such as numbers in an organized way. Binary search trees allow binary search for 
fast lookup, addition and removal of data items, and can be used to implement dynamic sets and lookup tables. The order of nodes in a BST means that each comparison skips about half of the remaining tree, 
so the whole lookup takes time proportional to the binary logarithm of the number of items stored in the tree. This is much better than the linear time required to find items by key in an (unsorted) array, 
but slower than the corresponding operations on hash tables.

In BST insertion and searching operation takes always O(logN) time complexity.

During the deletion of node from BST we might find ourself in 3 sort of different stiuation. Let's consider them one by one.

1) Node we wanna delete is a leaf node. Leaf node of tree is the node which does not have any child node. So in this case our job is gonna be very easy. Basically we will just set that node to null and that is all. Time 
complexity of this is gonna be O(logN) .
2) The node we wanna delete might have only 1 child. Does not matter on the right or left. It is also very easy job for us. We will replace this node with its that only child. And that is all. It will
also reqire O(logN) .
3) The node we wanna delete has 2 child. This is a little bit complex stiuation for us. There are several ways to handle this. One of the easiest way is below:
Just after finding the node we wanna remove will either the bigest node in the left subtree of that or smallest node in the right subtree of that and swap them. After that we will absolutely have one of the stiuation above for the node
we wanted delete. And we know how to handle them. So it will also take O(logN) time complexity.


Traversal of BST
The method to chouse to traverse the BST might be important. There some common ways to do it.
1) In-order traversal. With this method we start from left node then go to root then go to right recursively. It will give us sorted traversal.
2) Pre-order traversal. With this method we visit root then go to left then right recursively.
3) Post-order traversal. With this method we first visit left then go to right then root recursively.

Generally if the tree becomes very unbalances (for example we create a treee from sorted arrays then it will have only right childs) all the O(logN) operations are going to closer to O(N) linear time complexity. That is why
it is very important to keep tree as much as possible balanced.

Predecessor - > The bigest Item on the left subtree of given node
Successor -> The smallest item on the right sub tree of given node

5. BALANCED TREE AVL TREE

We learned that BST are way to better than LinkedList for searching operations but in the case it is balanced. If we would create a BST from sorted array we will not get balanced BST
instead we will get LinkedList which will give us O(N) time complexity for searching. But AVL tree is balanced BST. So AVL Tree are BST only with 1 important differ. If tree is AVL 
height of 2 child subtree of every node differ by at most one. So it condition never let tree become unbalanced it will alwys make sure tree is balanced.

All the operations are same in AVL tree with BST. (Because eventually AVL is BST tree). Only differ is during the adding new node to Tree we will need check whether tree remains balanced
or we should adjust it. AVL tree are faster than Red Black tree (Red Black tree is also BST) but construction is more difficult than that. That is why nowadays Red Black trees are more popular.

In Order to keep AVL balanced we might need rotations.
We might have 4 kind of cases.
1) Left heavy -> Node has left child and that left child olsa has left child
Solution. We should rotate the root (root of this subtree) to right.

2) Right heavy -> Node has right node and that right has also right. 
Solution. We shodul rotate the left

3) Left - right -> Node has left and that left has only right child.
Solution. First take left of root and rotate to left. After that we will have the case as same as 1st case (heavy left). To solve this ofcourse rotate root to right.

4) Right - left -> Node has right and that right has only left child.
Solution. First right of root and rotate to right. Then we will have case as same as 2nd (heavy right). To solve this rotate the root to left.


Operations of AVL Tree

insert() - > O(N * logN) time complexity. because after adding new value We should check the tree whther it is balanced or not. So of not we will need rotate the some nodes in order to
achive balanced tree. And in worst cases we might need to rotate all the nodes in the tree that is why we consider time complexity of insertion operation is O(N * logN);

Traversal -> O(logN) as same as normal BST.

Red black trees are more papular than AVL tree becuse after every insertion or deletion we might need rotate some nodes.


6. RED BLACK TREE
Red-black tree is also BST as well as AVL Tree. And it helps us to solve same problem related BST. Because when BST get unbalanced it louses its efficiency RED-BLACK tree tries to keep BST unbalanced. So Red-black tree is
balanced BST as same as AVL tree is.

Properties of Red-black tree
1) Each node is eidher RED or BLACK
2) The root node is always BLACK.
3) Every RED node should have 2 BLACK childs. (Children of RED should be BLACK). And of courses in this cases RED nodes will have always BLACK parent. 
4) Every path from given node to any of its descentant (NIL/NULL) noded should contain same number of BLACK nodes.

RED BLACK Tree vs AVL Tree

Red-black tree
- Linux Kernel relies on heavly Red-black tree data structure
- Insertion is fast Because it is not rigidly balanced. We dont bother to keep tree as balanced as possible
- For an insert intensive task use Red-black tree
- java.util.TreeMap, java.util.TreeSet uses Red-black tree data structure 

AVL Tree
- Rigidly balanced tree and hense provides faster look-up operation
- For a look-up intensive task use AVL
- Insertion and deletion is not so fast because we keep balancing the tree.

After insertion we should check nodes from bottom to top whether Is there red-black tree properties violation. If there we shoud fix it with help of rotation and recoloring. When we insert new node
into Tree its default color is red. So after insertion during the checking we might have same kind of case which we have different type solution for them.

CASE 1.
a) Inserted node is the right child of its parent, its parent is the left child of its parent, parent and uncle (uncle node is other child of nodes grandfather) are RED.
SOLUTION: Recoloring its parent, grandparent and uncle node. So After coloring parent and uncle are going to be BLACK, grandparent is going to be RED.

b) Inserted node is left child of its parent, its parent is right child of its parent and parent and uncle node are RED. 
SOLUTION: Recoloring Its parent, grandparent and uncle color. So after recoloring operation parent and uncle are going to be BLACK, grandparent is going to be RED;

CASE 2.
a) Inserted node is a right child, parent is left. Parent is RED, uncle is BLACK.
Solution: Left rotation of parent node.

b) Inserted node is left child, parent is right. Parent is RED,uncle is BLACK.
Solution: Right rotation of parent.

CASE 3.
a) Inserted node is left child, parent is left child. parent is RED, uncle is BLACK.
Solution: First we should Right rotate the gradparent then swap the color of parent and grandfather

b) Inserted node is right child, parent is right child. Parent is RED, uncle is BLACK.
Solution: First left rotation of grandparent then swap the colors of grandparent an parent.

CASE 4:
a) Inserted node is left child, parent is left child. Parent is RED and uncle is RED.
Solution: Recoloring parent to BLACK, uncle to BLACK and grandparent to RED;

b) Inserted node is right child, parent is right child. Parent is RED and uncle is RED.
Solution: Recoloring parent to BLACK, uncle to BLACK, grandparent to RED.



7. SPLAY TREE

Splay tree is al BST so all properties which were true for BST are the same for Splay tree. But splay tree is a little bit different from other special trype of BST which we learned such as AVl and Red-Black tree. Because aim of them were
keeping tree as balanced as possible. Specially AVL tree is very serious about it. But it is not the aim of the Splay tree. Aim of Splay tree is providing very fast to the items which were accessed recently.

About Splay tree
- It is type of Binary search treee(BST)
- Most operations have O(logN) complexity but some are very slow O(N)
- Unlike AVL tree it is not stricly balanced that is why it is faster
- It is easy to implement
- The most popular data strucre in the industry
- Fast access to the elements which were accessed recently
- It can be used for Cache implemetation

FIND operation
Find operation is exactly the same as how it is for General BST but with only one difference. After finding the item in the tree we should move it to the root of the by help of rotations. In this way for the next find operations this item
will be ble to be accedded very fast. Because it 'll be root. And it is called "splaying". We might need to make several rotation operation in order to move it to root.

After finding the item in the tree in order to make a rotation we should choouse which strateg to use. Because we might have 3 kind of cases there.
1) Zig-zag
2) Zig-zig
3) Zig


ZIG-ZAG
a) The item is left child , parent of it is right child.
SOLUTION: Right rotation of the item.

b) The item is right child , parent is left child.
SOLUTION: Left rotation of the item.


ZIG-ZIG
a) The item is left child, parent is left as well.
SOLUTION: Right rotation of the item
b) The item is right child, parent is right as well.
SOLUTION: Left rotation of the item

ZIG
a) The item is the left child of the root
SOLUTION: Right rotation of the item

b) The item is the right child of the root
SOLUTION: Left rotation the item

NOTE: Bsically if the node is the left child just rotate to right, but if the item if the right child just rotate to the left.




































